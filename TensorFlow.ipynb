{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import unittest\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/king/differentiation')\n",
    "\n",
    "from graph import Graph\n",
    "from session import Session\n",
    "\n",
    "class GradientsTestCase(unittest.TestCase):\n",
    "\n",
    "    def test_add_grad(self):\n",
    "        graph = Graph()\n",
    "\n",
    "        a = graph.tensor()\n",
    "        b = graph.tensor()\n",
    "        c = a + b\n",
    "\n",
    "        grad_a, grad_b = graph.gradients(c, [a, b])\n",
    "\n",
    "        sess = Session(graph)\n",
    "        grad_a_, grad_b_ = sess.run([grad_a, grad_b], feed_dict={a: 2, b: 1})\n",
    "\n",
    "        self.assertEqual(grad_a_, 1)\n",
    "        self.assertEqual(grad_b_, 1)\n",
    "\n",
    "    def test_sub_grad(self):\n",
    "        graph = Graph()\n",
    "\n",
    "        a = graph.tensor()\n",
    "        b = graph.tensor()\n",
    "        c = a - b\n",
    "\n",
    "        grad_a, grad_b = graph.gradients(c, [a, b])\n",
    "\n",
    "        sess = Session(graph)\n",
    "        grad_a_, grad_b_ = sess.run([grad_a, grad_b], feed_dict={a: 2, b: 1})\n",
    "\n",
    "        self.assertEqual(grad_a_, 1)\n",
    "        self.assertEqual(grad_b_, -1)\n",
    "\n",
    "    def test_mul_grad(self):\n",
    "        graph = Graph()\n",
    "\n",
    "        a = graph.tensor()\n",
    "        b = graph.tensor()\n",
    "        c = a * b\n",
    "\n",
    "        grad_a, grad_b = graph.gradients(c, [a, b])\n",
    "\n",
    "        sess = Session(graph)\n",
    "        grad_a_, grad_b_ = sess.run([grad_a, grad_b], feed_dict={a: 2, b: 3})\n",
    "\n",
    "        self.assertEqual(grad_a_, 3)\n",
    "        self.assertEqual(grad_b_, 2)\n",
    "\n",
    "    def test_div_grad(self):\n",
    "        graph = Graph()\n",
    "\n",
    "        a = graph.tensor()\n",
    "        b = graph.tensor()\n",
    "        c = a / b\n",
    "\n",
    "        grad_a, grad_b = graph.gradients(c, [a, b])\n",
    "\n",
    "        sess = Session(graph)\n",
    "        grad_a_, grad_b_ = sess.run([grad_a, grad_b], feed_dict={a: 2, b: 3})\n",
    "\n",
    "        self.assertAlmostEqual(grad_a_, 0.3333333)\n",
    "        self.assertAlmostEqual(grad_b_, -0.2222222)\n",
    "\n",
    "    def test_square_grad(self):\n",
    "        graph = Graph()\n",
    "\n",
    "        a = graph.tensor()\n",
    "        b = graph.square(a)\n",
    "\n",
    "        grad, = graph.gradients(b, [a])\n",
    "\n",
    "        sess = Session(graph)\n",
    "        grad_, = sess.run([grad], feed_dict={a: 6})\n",
    "\n",
    "        self.assertEqual(grad_, 12)\n",
    "\n",
    "    def test_sigmoid_grad(self):\n",
    "        graph = Graph()\n",
    "\n",
    "        a = graph.tensor()\n",
    "        b = graph.sigmoid(a)\n",
    "\n",
    "        grad, = graph.gradients(b, [a])\n",
    "\n",
    "        sess = Session(graph)\n",
    "        grad_, = sess.run([grad], feed_dict={a: 1})\n",
    "\n",
    "        self.assertAlmostEqual(grad_, 0.19661193)\n",
    "\n",
    "    def test_neg_grad(self):\n",
    "        graph = Graph()\n",
    "\n",
    "        a = graph.tensor()\n",
    "        b = -a\n",
    "\n",
    "        grad, = graph.gradients(b, [a])\n",
    "\n",
    "        sess = Session(graph)\n",
    "        grad_, = sess.run([grad], feed_dict={a: 1})\n",
    "\n",
    "        self.assertEqual(grad_, -1)\n",
    "\n",
    "    def test_dot_grad(self):\n",
    "        graph = Graph()\n",
    "\n",
    "        a = graph.tensor(np.array([0, 1, 2, 3]).reshape((1, -1)))\n",
    "        b = graph.tensor(np.array([0, 1, 2, 3]).reshape((-1, 1)))\n",
    "        c = graph.dot(a, b)\n",
    "\n",
    "        grad_a, grad_b, = graph.gradients(c, [a, b])\n",
    "\n",
    "        sess = Session(graph)\n",
    "        grad_a_, grad_b_ = sess.run([grad_a, grad_b])\n",
    "\n",
    "        self.assertTrue(np.array_equal(grad_a_, np.array([[0, 1, 2, 3]])))\n",
    "        self.assertTrue(np.array_equal(grad_b_, np.array([[0], [1], [2], [3]])))\n",
    "\n",
    "    def test_transpose_grad(self):\n",
    "        graph = Graph()\n",
    "\n",
    "        a = graph.tensor(np.array([[0, 1, 2, 3]]))\n",
    "        b = graph.transpose(a)\n",
    "\n",
    "        grad, = graph.gradients(b, [a])\n",
    "\n",
    "        sess = Session(graph)\n",
    "        grad_, = sess.run([grad])\n",
    "\n",
    "        self.assertEqual(grad_, 1)\n",
    "\n",
    "    def test_mean_grad(self):\n",
    "        graph = Graph()\n",
    "\n",
    "        a = graph.tensor(np.array([[0, 2, 4, 6]]))\n",
    "        b = graph.mean(a)\n",
    "\n",
    "        grad, = graph.gradients(b, [a])\n",
    "\n",
    "        sess = Session(graph)\n",
    "        grad_, = sess.run([grad])\n",
    "\n",
    "        # XXX: This is intentionally incorrect.\n",
    "        self.assertEqual(grad_, 1)\n",
    "\n",
    "    def test_expression_grad(self):\n",
    "        graph = Graph()\n",
    "\n",
    "        a = graph.tensor()\n",
    "        b = graph.tensor()\n",
    "\n",
    "        c = a + b\n",
    "        d = b + 1\n",
    "        e = c * d\n",
    "\n",
    "        de_da, de_db = graph.gradients(e, [a, b])\n",
    "\n",
    "        sess = Session(graph)\n",
    "\n",
    "        a_, b_, c_, d_, e_, de_da_, de_db_ = sess.run([a, b, c, d, e, de_da, de_db], feed_dict={a: 2, b: 1})\n",
    "\n",
    "        self.assertEqual(a_, 2)\n",
    "        self.assertEqual(b_, 1)\n",
    "        self.assertEqual(c_, 3)\n",
    "        self.assertEqual(d_, 2)\n",
    "        self.assertEqual(e_, 6)\n",
    "        self.assertEqual(de_da_, 2)\n",
    "        self.assertEqual(de_db_, 5)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-c8bd80650530>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-5-c8bd80650530>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    print sys.path\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_add_grad (__main__.GradientsTestCase) ... ok\n",
      "test_div_grad (__main__.GradientsTestCase) ... ok\n",
      "test_dot_grad (__main__.GradientsTestCase) ... ok\n",
      "test_expression_grad (__main__.GradientsTestCase) ... ok\n",
      "test_mean_grad (__main__.GradientsTestCase) ... ok\n",
      "test_mul_grad (__main__.GradientsTestCase) ... ok\n",
      "test_neg_grad (__main__.GradientsTestCase) ... ok\n",
      "test_sigmoid_grad (__main__.GradientsTestCase) ... ok\n",
      "test_square_grad (__main__.GradientsTestCase) ... ok\n",
      "test_sub_grad (__main__.GradientsTestCase) ... ok\n",
      "test_transpose_grad (__main__.GradientsTestCase) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 11 tests in 0.041s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x7fab32b41d90>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=['ignored', '-v'], exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "queue = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "queue.append(([1,1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 1], 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queue.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grads={1,2,3,4,0,9,8,7}\n",
    "test = {'a','b','z','x'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "a\n",
      "1\n",
      "x\n",
      "2\n",
      "z\n",
      "3\n",
      "b\n"
     ]
    }
   ],
   "source": [
    "for t,g in zip(test,grads):\n",
    "\n",
    "    print(g)\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "for g in grads:\n",
    "    print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Tensor(object):\n",
    "    \"\"\"docstring for tensor\"\"\"\n",
    "    def __init__(self, initial_value,op,graph):\n",
    "        self.initial_value = initial_value\n",
    "        self.graph = graph\n",
    "        self.op = op\n",
    "\n",
    "    def __add__(self, other): # change the + operateor's methods, other is another self \n",
    "        return self.graph.add(self, other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class BaseOp(object):\n",
    "    \"\"\"docstring for BaseOp\"\"\"\n",
    "    def __init__(self, inputs,graph):\n",
    "        self.inputs = [graph.convert(input_) for input_ in inputs]\n",
    "        self.output = graph.tensor(op=self)\n",
    "        self.graph  = graph\n",
    "\n",
    "    def compute(self,*args):\n",
    "        raise NotImplementedError()\n",
    "    def gradient(self,grad):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "class AddOp(BaseOp):\n",
    "\n",
    "    def compute(self,a=0,b=0):\n",
    "        a = self.inputs[0].initial_value\n",
    "        b = self.inputs[1].initial_value\n",
    "        return a + b\n",
    "    def gradient(self,grad):\n",
    "        return [grad,grad]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Graph(object):\n",
    "\t\"\"\"docstring for Graph\"\"\"\n",
    "\tdef tensor(self,initial_value=None,op=None):\n",
    "\t\treturn Tensor(initial_value=initial_value,op=op,graph=self)\n",
    "\n",
    "\tdef convert(self,value):\n",
    "\t\tif isinstance(value,Tensor):\n",
    "\t\t\treturn value\n",
    "\t\treturn self.tensor(initial_value=value)\n",
    "\n",
    "\tdef gradients(self,y,x_s):\n",
    "\n",
    "\t\t'''\n",
    "\t\t>>>queue.append(([1,1],1))\n",
    "\t\t>>>queue.pop(0)\n",
    "\t\t([1, 1], 1)\n",
    "\n",
    "\n",
    "\n",
    "    \tloss_op = graph.mean(graph.square(graph.transpose(y) - activations1))\n",
    "    \tparameters = [weights0, biases0, weights1, biases1]\n",
    "\n",
    "    \tgradients = graph.gradients(loss_op, parameters)\n",
    "\t\t'''\n",
    "\t\tqueue = []\n",
    "\t\tqueue.append((y,1))\n",
    "\n",
    "\t\tgrads = {}\n",
    "\n",
    "\t\twhile len(queue)>0:\n",
    "\t\t\ty,grad_y = queue.pop(0)\n",
    "\t\t\tgrad_y = self.convert(grad_y) #convert grad_y to a tensor\n",
    "\n",
    "\t\t\tgradients = y.op.gradient(grad_y)\n",
    "\t\treturn gradients\n",
    "\n",
    "\tdef add(self,a,b):\n",
    "\t\top = AddOp([a,b],graph=self)\n",
    "\t\treturn op.output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_graph = Graph()\n",
    "test_X = test_graph.tensor([1,1],AddOp) \n",
    "test_Y = test_graph.tensor([2,2],AddOp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Tensor object at 0x7fab31b86d10>\n",
      "<__main__.Tensor object at 0x7fab31b86990>\n",
      "[1, 1]\n",
      "[2, 2]\n",
      "<class '__main__.AddOp'>\n",
      "<class '__main__.AddOp'>\n"
     ]
    }
   ],
   "source": [
    "print(test_X)\n",
    "print(test_Y)\n",
    "print(test_X.initial_value)\n",
    "print(test_Y.initial_value)\n",
    "print(test_X.op)\n",
    "print(test_Y.op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1]\n",
      "[2, 2]\n"
     ]
    }
   ],
   "source": [
    "test_Z = test_X + test_Y # Tensor.__add__ --> graph.add  -->AddOp(inputs = [a,b]) --> BaseOp.__initial__.inputs[]\n",
    "print(test_Z.op.inputs[0].initial_value)\n",
    "print(test_Z.op.inputs[1].initial_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "print(test_Z.op.compute()) #test_X = test_graph.tensor([1,1],AddOp) -->op is AddOp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 2, 2]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1,1]+[2,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "None\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(test_graph.gradients(test_Z,0)[0].initial_value)\n",
    "print(test_graph.gradients(test_Z,0)[1].initial_value)\n",
    "print(test_graph.gradients(test_Z,0)[0].op)\n",
    "print(test_graph.gradients(test_Z,0)[0].graph.gradients(test_Z,0)[0].initial_value)\n",
    "print(test_graph.gradients(test_Z,0)[0].graph.gradients(test_Z,0)[0].graph.gradients(test_Z,0)[0].initial_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class A(object):\n",
    "    def __init__(self):\n",
    "        print(\"A\")\n",
    "    def testA(self):\n",
    "        print( \"A class function\")\n",
    "        B.testB()\n",
    "\n",
    "class B(object):\n",
    "    def __init__(self):\n",
    "        print(\"B\")\n",
    "    def testB(self):\n",
    "        print( \"B class function\")\n",
    "        A.testA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B\n",
      "A\n"
     ]
    }
   ],
   "source": [
    "\n",
    "B = B()\n",
    "A = A()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Session(object):\n",
    "    def __init__(self, graph):\n",
    "        self.graph = graph\n",
    "        self.state = {}\n",
    "    def run_op(self, op, context):\n",
    "        args = [self.eval_tensor(tensor, context) for tensor in op.inputs]\n",
    "        return op.compute(self, *args)\n",
    "    def eval_tensor(self, tensor, context):\n",
    "        \n",
    "        if tensor not in context:\n",
    "            if tensor.op is not None:\n",
    "                context[tensor] = self.run_op(tensor.op, context)\n",
    "            elif tensor in self.state and self.state[tensor] is not None:\n",
    "                context[tensor] = self.state[tensor]\n",
    "            elif tensor not in self.state and tensor.initial_value is not None:\n",
    "                context[tensor] = self.state[tensor] = tensor.initial_value\n",
    "\n",
    "        return context[tensor]\n",
    "    def run(self, tensors, feed_dict=None):\n",
    "        \n",
    "        context = {}\n",
    "\n",
    "        if feed_dict:\n",
    "            context.update(feed_dict)\n",
    "\n",
    "        return [self.eval_tensor(tensor, context) for tensor in tensors]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Session(object):\n",
    "    def __init__(self, graph):\n",
    "        self.graph = graph\n",
    "        self.state = {}\n",
    "        \n",
    "    def run_op(self, op, context):\n",
    "        args = [self.eval_tensor(tensor, context) for tensor in op.inputs]\n",
    "        return op.compute(self, *args)\n",
    "    \n",
    "    def eval_tensor(self, tensor, context):\n",
    "        \n",
    "        if tensor not in context:\n",
    "            if tensor.op is not None:\n",
    "                context[tensor] = self.run_op(tensor.op, context)\n",
    "            elif tensor in self.state and self.state[tensor] is not None:\n",
    "                context[tensor] = self.state[tensor]\n",
    "            elif tensor not in self.state and tensor.initial_value is not None:\n",
    "                context[tensor] = self.state[tensor] = tensor.initial_value\n",
    "\n",
    "        return context[tensor]\n",
    "    def run(self, tensors, feed_dict=None):\n",
    "        \n",
    "        context = {}\n",
    "\n",
    "        if feed_dict:\n",
    "            context.update(feed_dict)\n",
    "\n",
    "        return [self.eval_tensor(tensor, context) for tensor in tensors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'set' object has no attribute '__getitem__'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-f14b5c565efd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mtensor2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mAddOp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mcontext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m \u001b[0mtensor1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtensor2\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mcontext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'set' object has no attribute '__getitem__'"
     ]
    }
   ],
   "source": [
    "#sess = Session(graph)\n",
    "#loss_op = graph.mean(graph.square(graph.transpose(y) - activations1))\n",
    "#update_op = graph.group([\n",
    "    #graph.assign(param, param - grad) \\\n",
    "    #        for param, grad in zip(parameters, gradients)])\n",
    "    #_, loss = sess.run([update_op, loss_op])\n",
    "\n",
    "test_graph = Graph()\n",
    "test_X = test_graph.tensor([1,1],AddOp) \n",
    "test_Y = test_graph.tensor([2,2],AddOp)\n",
    "context = {}\n",
    "tensor = Tensor([1,1],AddOp,test_graph)\n",
    "tensor1 = Tensor([1,1],AddOp,test_graph)\n",
    "tensor2 = Tensor([1,1],AddOp,test_graph)\n",
    "context = { tensor1,tensor2}\n",
    "context[tensor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph = Graph()\n",
    "x = graph.tensor(np.array(1))\n",
    "y = graph.tensor(np.array(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Tensor object at 0x7f4b4c0609d0>\n"
     ]
    }
   ],
   "source": [
    "w = graph.tensor(np.zeros(1))\n",
    "b= graph.tensor(np.zeros(1))\n",
    "print w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object <genexpr> at 0x7f4b33b4b370>\n",
      "<generator object <genexpr> at 0x7f4b33b4b6e0>\n",
      "[1 2]\n"
     ]
    }
   ],
   "source": [
    "loss_op = x + w + y + b\n",
    "context = graph.add(loss_op,x)\n",
    "parameters = [w,b]\n",
    "gradients = graph.gradients(loss_op, parameters)\n",
    "\n",
    "\n",
    "sess = Session(graph)\n",
    "#_, loss = sess.run([gradients, context])\n",
    "\n",
    "test = graph.tensor(np.array([1,2]))\n",
    "test2 = graph.tensor(np.array([3,4]))\n",
    "test3 = graph.tensor(np.array([5,6]))\n",
    "context = {test ,test2,test3}\n",
    "#_, loss = sess.run([test, context])\n",
    "t={1,2,3}\n",
    "print(a for a in t)\n",
    "print(tensor.initial_value for tensor in context)\n",
    "print(test.initial_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
