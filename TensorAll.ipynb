{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Tensor(object):\n",
    "    \"\"\"docstring for tensor\"\"\"\n",
    "    def __init__(self, initial_value,op,graph):\n",
    "        self.initial_value = initial_value\n",
    "        self.graph = graph\n",
    "        self.op = op\n",
    "\n",
    "    def __add__(self, other): # change the + operateor's methods, other is another self \n",
    "        return self.graph.add(self, other)\n",
    "    \n",
    "    def __neg__(self):\n",
    "        return self.graph.neg(self)\n",
    "    \n",
    "    def __sub__(self, other):\n",
    "        return self.graph.sub(self, other)\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        return self.graph.mul(self, other)\n",
    "    \n",
    "    def __truediv__(self, other):\n",
    "        return self.graph.div(self, other)\n",
    "    \n",
    "    # ## [Reverse Operator Overloading](https://docs.python.org/2/reference/datamodel.html?highlight=__radd__#object.__radd__)\n",
    "    def __radd__(self, other):\n",
    "        return self.graph.add(other, self)\n",
    "\n",
    "    def __rsub__(self, other):\n",
    "        return self.graph.sub(other, self)\n",
    "\n",
    "    def __rmul__(self, other):\n",
    "        return self.graph.mul(other, self)\n",
    "\n",
    "    def __rtruediv__(self, other):\n",
    "        return self.graph.div(other, self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class BaseOp(object):\n",
    "    \"\"\"docstring for BaseOp\"\"\"\n",
    "    def __init__(self, inputs,graph):\n",
    "        self.inputs = [graph.convert(input_) for input_ in inputs]\n",
    "        self.output = graph.tensor(op=self)\n",
    "        self.graph  = graph\n",
    "\n",
    "    def compute(self,sess,*args):\n",
    "        raise NotImplementedError()\n",
    "    def gradient(self,grad):\n",
    "        raise NotImplementedError()\n",
    "'''\n",
    "class myParent( object ):\n",
    "    def __init__( self, customParam ):\n",
    "        self.parentNumber = 5\n",
    "        self.customParam = customParam\n",
    "\n",
    "class Child( myParent ):\n",
    "    def __init__( self, customParam ):\n",
    "        myParent.__init__( self, customParam )\n",
    "        self.childNumber = 4        \n",
    "'''        \n",
    "        \n",
    "class AddOp(BaseOp):\n",
    "\n",
    "    \n",
    "    def __init__(self, inputs,graph):\n",
    "        BaseOp.__init__(self, inputs,graph)\n",
    "        self.output = graph.convert(   self.compute(inputs[0],inputs[1])   ) #build a tensor object but no op\n",
    "        self.output_tensor_with_op = graph.tensor(   self.compute(inputs[0],inputs[1]),op =self) # build tensor with op=self\n",
    "        '''\n",
    "        print(\"11111111111 is :\"+str(inputs[0].initial_value))\n",
    "        if inputs[0] is not None and inputs[1] is not None:\n",
    "            self.output = graph.convert(   self.compute(inputs[0],inputs[1])   )\n",
    "        #self.output = graph.convert(1000000000000000000000000000000)\n",
    "    '''\n",
    "    def compute(self,a=0,b=0):\n",
    "        #a = self.inputs[0].initial_value\n",
    "        #b = self.inputs[1].initial_value\n",
    "        return a.initial_value + b.initial_value\n",
    "    def gradient(self,grad):\n",
    "        return [grad,grad]\n",
    "    \n",
    "    \n",
    "    \n",
    "class NegOp(BaseOp):\n",
    "    \"\"\"\n",
    "    `NegOp` negates a tensor.\n",
    "    \"\"\"\n",
    "    def __init__(self, inputs,graph):\n",
    "        BaseOp.__init__(self, inputs,graph)\n",
    "        self.output = graph.convert(   self.compute(inputs[0])   ) #build a tensor object but no op\n",
    "        self.output_tensor_with_op = graph.tensor(   self.compute(inputs[0]),op =self) # build tensor with op=self\n",
    "    \n",
    "    def compute(self,  x):\n",
    "        return -x.initial_value\n",
    "\n",
    "    def gradient(self, grad):\n",
    "        return [-grad]\n",
    "\n",
    "    \n",
    "class SubOp(BaseOp):\n",
    "    \"\"\"\n",
    "    `SubOp` subtracts a tensor from another tensor. Also uses the\n",
    "    [sum rule](https://en.wikipedia.org/wiki/Sum_rule_in_differentiation) to\n",
    "    compute the partial derivatives.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, inputs,graph):\n",
    "        BaseOp.__init__(self, inputs,graph)\n",
    "        self.output = graph.convert(   self.compute(inputs[0],inputs[1])   ) #build a tensor object but no op\n",
    "        self.output_tensor_with_op = graph.tensor(   self.compute(inputs[0],inputs[1]),op =self) # build tensor with op=self\n",
    "    \n",
    "    \n",
    "    def compute(self, a, b):\n",
    "        return a.initial_value - b.initial_value\n",
    "\n",
    "    def gradient(self, grad):\n",
    "        return [grad, -grad]\n",
    "    \n",
    "    \n",
    "class MulOp(BaseOp):\n",
    "    \"\"\"\n",
    "    `MulOp` multiplies a tensor by another tensor. Uses the\n",
    "    [product rule](https://en.wikipedia.org/wiki/Product_rule) to compute the\n",
    "    partial derivatives.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, inputs,graph):\n",
    "        BaseOp.__init__(self, inputs,graph)\n",
    "        self.output = graph.convert(   self.compute(inputs[0],inputs[1])   ) #build a tensor object but no op\n",
    "        self.output_tensor_with_op = graph.tensor(   self.compute(inputs[0],inputs[1]),op =self) # build tensor with op=self\n",
    "    \n",
    "\n",
    "    def compute(self, a, b):\n",
    "        return a.initial_value * b.initial_value\n",
    "\n",
    "    def gradient(self, grad):\n",
    "        a, b = self.inputs\n",
    "        return [grad * b, grad * a]\n",
    "    \n",
    "    \n",
    "class SquareOp(BaseOp):\n",
    "    \"\"\"\n",
    "    `SquareOp` squares a tensor.\n",
    "    \"\"\"\n",
    "    def __init__(self, inputs,graph):\n",
    "        BaseOp.__init__(self, inputs,graph)\n",
    "        self.output = graph.convert(   self.compute(inputs[0])   ) #build a tensor object but no op\n",
    "        self.output_tensor_with_op = graph.tensor(   self.compute(inputs[0]),op =self) # build tensor with op=self\n",
    "    \n",
    "\n",
    "    def compute(self,  x):\n",
    "        return np.square(x)\n",
    "\n",
    "    def gradient(self, grad):\n",
    "        x = self.inputs[0].initial_value\n",
    "        return [grad * (2 * x)]\n",
    "    \n",
    "class DivOp(BaseOp):\n",
    "    \"\"\"\n",
    "    `DivOp` divides a tensor by another tensor. Uses the\n",
    "    [quotient rule](https://en.wikipedia.org/wiki/Quotient_rule) to compute the\n",
    "    partial derivatives.\n",
    "    \"\"\"\n",
    "    def __init__(self, inputs,graph):\n",
    "        BaseOp.__init__(self, inputs,graph)\n",
    "        #self.output = graph.convert(   self.compute(inputs[0],inputs[1])   ) #build a tensor object but no op\n",
    "        self.output_tensor_with_op = graph.tensor(   self.compute(inputs[0],inputs[1]),op =self) # build tensor with op=self\n",
    "    \n",
    "\n",
    "    def compute(self, a, b):\n",
    "\n",
    "        if type(a) is int:\n",
    "            print(\"@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\")\n",
    "            print(type(a))\n",
    "            temp = a/b\n",
    "        else:\n",
    "            print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "            print(type(a))\n",
    "            print(type(b))\n",
    "            print(a.initial_value)\n",
    "            print(b.initial_value)\n",
    "            temp = a.initial_value/b.initial_value\n",
    "        return temp\n",
    "    def gradient(self, grad):\n",
    "        a_, b_ = self.inputs\n",
    "        a=a_.initial_value\n",
    "        b=b_.initial_value\n",
    "        grad_=grad.initial_value\n",
    "        print(\"%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\")\n",
    "        print(type(a))\n",
    "        print(type(b))\n",
    "        print(type(grad))\n",
    "        #grad_=self.graph.tensor(grad)\n",
    "        return [self.graph.tensor(grad_ / b), self.graph.tensor( grad_ * (-a / self.graph.square(b).initial_value)) ] \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "class TransposeOp(BaseOp):\n",
    "    \"\"\"\n",
    "    `TransposeOp` tranposes a tensor.\n",
    "    \"\"\"\n",
    "    def __init__(self, inputs,graph):\n",
    "        BaseOp.__init__(self, inputs,graph)\n",
    "        #self.output = graph.convert(   self.compute(inputs[0],inputs[1])   ) #build a tensor object but no op\n",
    "        self.output_tensor_with_op = graph.tensor(   self.compute(inputs[0]),op =self) # build tensor with op=self\n",
    "    \n",
    "\n",
    "    def compute(self, x):\n",
    "        return np.transpose(x)\n",
    "\n",
    "    def gradient(self, grad):\n",
    "        return [self.graph.transpose(grad)]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "class DotOp(BaseOp):\n",
    "    \"\"\"\n",
    "    `DotOp` computes the dot product between two tensors. Uses the\n",
    "    [product rule](https://en.wikipedia.org/wiki/Product_rule) to compute the\n",
    "    partial derivatives. Note that here we need to transpose the terms and\n",
    "    perform a dot product, assuming matrices rather than scalars.\n",
    "    \"\"\"\n",
    "    def __init__(self, inputs,graph):\n",
    "        BaseOp.__init__(self, inputs,graph)\n",
    "        #self.output = graph.convert(   self.compute(inputs[0],inputs[1])   ) #build a tensor object but no op\n",
    "        self.output_tensor_with_op = graph.tensor(   self.compute(inputs[0],inputs[1]),op =self) # build tensor with op=self\n",
    "    \n",
    "\n",
    "    def compute(self, a, b):\n",
    "        return np.dot(a, b)\n",
    "\n",
    "    def gradient(self, grad):\n",
    "        a, b = self.inputs\n",
    "        aT = self.graph.transpose(a)\n",
    "        bT = self.graph.transpose(b)\n",
    "        return [\n",
    "            self.graph.dot(grad, bT),\n",
    "            self.graph.dot(aT, grad),\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Graph(object):\n",
    "\t\"\"\"docstring for Graph\"\"\"\n",
    "\tdef tensor(self,initial_value=None,op=None):\n",
    "\t\treturn Tensor(initial_value=initial_value,op=op,graph=self)\n",
    "\n",
    "\tdef convert(self,value):\n",
    "\t\tif isinstance(value,Tensor):\n",
    "\t\t\treturn value\n",
    "\t\treturn self.tensor(initial_value=value)\n",
    "\n",
    "\tdef gradients(self,y,x_s):\n",
    "\n",
    "\t\t'''\n",
    "\t\t>>>queue.append(([1,1],1))\n",
    "\t\t>>>queue.pop(0)\n",
    "\t\t([1, 1], 1)\n",
    "\n",
    "\n",
    "\n",
    "    \tloss_op = graph.mean(graph.square(graph.transpose(y) - activations1))\n",
    "    \tparameters = [weights0, biases0, weights1, biases1]\n",
    "\n",
    "    \tgradients = graph.gradients(loss_op, parameters)\n",
    "\t\t'''\n",
    "\t\tqueue = []\n",
    "\t\tqueue.append((y,1)) #queue = [(y,1)]\n",
    "\n",
    "\t\tgrads = {}\n",
    "\n",
    "\t\twhile len(queue)>0:   #len(queue) = 1\n",
    "\t\t\ty,grad_y = queue.pop(0)  # y=y,grad_y =1\n",
    "\t\t\tgrad_y = self.convert(grad_y) #convert grad_y = 1 to a tensor = 1\n",
    "\t\t\t#print(y.op)\n",
    "\n",
    "\t\t\tgradients = y.op.gradient(grad_y) #gradients = [grad_y = 1,grad_y = 1] grad_y is a tensor\n",
    "\t\t\tassert len(gradients) == len(y.op.inputs)#len(gradients) = 2, len(y.op.inputs) = 2, \n",
    "            #c = a + b + a + a + b/ y = c /  y.op.inputs is [a + b + a + a ,b]\n",
    "\n",
    "\t\t\tfor tensor, gradient in zip(y.op.inputs, gradients):\n",
    "                #zip( [a + b + a + a ,b] , [grad_y = 1,grad_y = 1]  )\n",
    "\t\t\t\tif tensor in grads:  # 1: tensor = a + b + a + a , grads = {} \n",
    "                    #2:tensor = b, grads={a + b + a + a:grad_y}\n",
    "\t\t\t\t\tgrads[tensor] += gradient\n",
    "\t\t\t\t\tprint(\"+=\")\n",
    "\t\t\t\t\tprint(tensor.op)\n",
    "\t\t\t\t\tprint(tensor.initial_value)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tgrads[tensor] = gradient # 1 : grads[a + b + a + a] = gradient(=grad_y) \n",
    "                    #2:grads[b] = gradient(=grad_y)\n",
    "\t\t\t\t\tprint(\"first 111111111111111111111\")\n",
    "\t\t\t\t\tprint(tensor.op)\n",
    "\t\t\t\t\tprint(tensor.initial_value)\n",
    "\n",
    "\t\t\t\tif tensor.op:\n",
    "\t\t\t\t\tqueue.append((tensor, gradient)) #queue=[(a + b + a + a,grad_y),(b,grad_y)]\n",
    "                    #**********************************************************\n",
    "                    # for b does not have a op, so tensor.op is None, so queue=[(a+b+a+a,grad_y)] \n",
    "                    # not have (b,grad_y)\n",
    "                    #**********************************************************\n",
    "                    \n",
    "                    \n",
    "            #while len(queue) = 2\n",
    "            #queue.pop(0) = (a + b + a + a,grad_y) => y = a + b + a + a ,grad_y=grad_y=1(tensor)\n",
    "            #......\n",
    "            #while len(queue) = 3\n",
    "            #queue.pop(0) = (b,grad_y) => y = b, grad_y = grad_y = 1\n",
    "            \n",
    "\n",
    "\t\treturn [grads[x] for x in x_s]\n",
    "\n",
    "\n",
    "\tdef add(self,a,b):\n",
    "\t\top = AddOp([a,b],graph=self)\n",
    "\t\treturn op.output_tensor_with_op\n",
    "    \n",
    "\tdef neg(self, x):\n",
    "\t\top = NegOp([x], graph=self)\n",
    "\t\treturn op.output_tensor_with_op\n",
    "    \n",
    "    \n",
    "\tdef sub(self, a, b):\n",
    "\t\top = SubOp([a, b], graph=self)\n",
    "\t\treturn op.output_tensor_with_op\n",
    "    \n",
    "\n",
    "    \n",
    "\tdef mul(self, a, b):\n",
    "\t\top = MulOp([a , b], graph=self)\n",
    "\t\treturn op.output_tensor_with_op\n",
    "    \n",
    "\tdef square(self, x):\n",
    "\t\top = SquareOp([x], graph=self)\n",
    "\t\treturn op.output_tensor_with_op\n",
    "    \n",
    "\tdef div(self, a, b):\n",
    "\t\top = DivOp([a, b], graph=self)\n",
    "\t\treturn op.output_tensor_with_op\n",
    "    \n",
    "    \n",
    "\tdef transpose(self, x):\n",
    "\t\top = TransposeOp([x], graph=self)\n",
    "\t\treturn op.output_tensor_with_op\n",
    "    \n",
    "\tdef dot(self, a, b):\n",
    "\t\top = DotOp([a, b], graph=self)\n",
    "\t\treturn op.output_tensor_with_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Session(object):\n",
    "    def __init__(self, graph):\n",
    "        self.graph = graph\n",
    "        self.state = {}\n",
    "        \n",
    "    def run_op(self, op, context):\n",
    "        args = [self.eval_tensor(tensor, context) for tensor in op.inputs]\n",
    "        return op.compute(self, *args)\n",
    "    \n",
    "    def eval_tensor(self, tensor, context):\n",
    "        \n",
    "        if tensor not in context:\n",
    "            if tensor.op is not None:\n",
    "                context[tensor] = self.run_op(tensor.op, context) #let context add the value in op.input\n",
    "            elif tensor in self.state and self.state[tensor] is not None:\n",
    "                context[tensor] = self.state[tensor]              #let context add the value in self.state\n",
    "            elif tensor not in self.state and tensor.initial_value is not None:\n",
    "                context[tensor] = self.state[tensor] = tensor.initial_value\n",
    "                                                        #let context add the value by the initial_value of tensor\n",
    "        return context[tensor]\n",
    "    def run(self, tensors, feed_dict=None):\n",
    "        \n",
    "        context = {}\n",
    "\n",
    "        if feed_dict:\n",
    "            context.update(feed_dict)\n",
    "\n",
    "        return [self.eval_tensor(tensor, context) for tensor in tensors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "==================\n",
      "None\n",
      "None\n",
      "<__main__.AddOp object at 0x7f0f40520610>\n",
      "==================\n",
      "Length is :2\n",
      "<__main__.MulOp object at 0x7f0f40520510>\n",
      "None\n",
      "10\n",
      "2\n",
      "12\n",
      "12\n",
      "==================\n",
      "12\n",
      "==================G\n",
      "first 111111111111111111111\n",
      "<__main__.MulOp object at 0x7f0f40520510>\n",
      "10\n",
      "first 111111111111111111111\n",
      "None\n",
      "2\n",
      "+=\n",
      "None\n",
      "2\n",
      "first 111111111111111111111\n",
      "None\n",
      "5\n",
      "6\n",
      "2\n",
      "==================\n",
      "c.op.inputs[0].op.inputs[0] = a + b + a\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "graph = Graph()\n",
    "a = graph.tensor(2)\n",
    "b = graph.tensor(5)\n",
    "c = a*b+a\n",
    "print(c.initial_value)\n",
    "print(\"==================\")\n",
    "print(a.op)\n",
    "print(b.op)\n",
    "print(c.op)\n",
    "print(\"==================\")\n",
    "print(\"Length is :\"+str(len(c.op.inputs)))\n",
    "print(c.op.inputs[0].op)\n",
    "print(c.op.inputs[1].op)\n",
    "print(c.op.inputs[0].initial_value)\n",
    "print(c.op.inputs[1].initial_value)\n",
    "print(c.op.output.initial_value)\n",
    "print(c.op.output_tensor_with_op.initial_value)\n",
    "print(\"==================\")\n",
    "print(c.initial_value)\n",
    "print(\"==================G\")\n",
    "grad_a, grad_b = graph.gradients(c, [a, b])\n",
    "print(grad_a.initial_value)\n",
    "print(grad_b.initial_value)\n",
    "print(\"==================\")\n",
    "print(\"c.op.inputs[0].op.inputs[0] = a + b + a\")\n",
    "print(c.op.inputs[0].op.inputs[0].initial_value)\n",
    "#print(c.op.inputs[0].op.inputs[1].initial_value)\n",
    "#sess = Session(graph)\n",
    "#grad_a_, grad_b_ = sess.run([grad_a, grad_b], feed_dict={a: 2, b: 1})\n",
    "#print(grad_a_)\n",
    "#print(grad_b_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "==================\n",
      "None\n",
      "None\n",
      "<__main__.MulOp object at 0x7f0f5c4d3790>\n",
      "==================\n",
      "Length is :2\n",
      "None\n",
      "2\n",
      "8\n",
      "8\n",
      "==================\n",
      "8\n",
      "==================G\n",
      "first 111111111111111111111\n",
      "None\n",
      "2\n",
      "first 111111111111111111111\n",
      "<__main__.AddOp object at 0x7f0f40511e10>\n",
      "4\n",
      "+=\n",
      "None\n",
      "2\n",
      "+=\n",
      "None\n",
      "2\n",
      "8\n",
      "==================\n",
      "c.op.inputs[0].op.inputs[0] = a + b + a\n"
     ]
    }
   ],
   "source": [
    "graph = Graph()\n",
    "a = graph.tensor(2)\n",
    "b = graph.tensor(5)\n",
    "c = a*(a + a )\n",
    "print(c.initial_value)\n",
    "print(\"==================\")\n",
    "print(a.op)\n",
    "print(b.op)\n",
    "print(c.op)\n",
    "print(\"==================\")\n",
    "print(\"Length is :\"+str(len(c.op.inputs)))\n",
    "print(c.op.inputs[0].op)\n",
    "print(c.op.inputs[0].initial_value)\n",
    "print(c.op.output.initial_value)\n",
    "print(c.op.output_tensor_with_op.initial_value)\n",
    "print(\"==================\")\n",
    "print(c.initial_value)\n",
    "print(\"==================G\")\n",
    "grad_a= graph.gradients(c, [a])\n",
    "print(grad_a[0].initial_value)\n",
    "print(\"==================\")\n",
    "print(\"c.op.inputs[0].op.inputs[0] = a + b + a\")\n",
    "#print(c.op.inputs[0].op.inputs[0].initial_value)\n",
    "#print(c.op.inputs[0].op.inputs[1].initial_value)\n",
    "#sess = Session(graph)\n",
    "#grad_a_, grad_b_ = sess.run([grad_a, grad_b], feed_dict={a: 2, b: 1})\n",
    "#print(grad_a_)\n",
    "#print(grad_b_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "==================\n",
      "None\n",
      "None\n",
      "<__main__.SubOp object at 0x7f0f4052d090>\n",
      "==================\n",
      "12\n",
      "5\n",
      "7\n",
      "7\n",
      "==================\n",
      "7\n",
      "==================G\n",
      "first 111111111111111111111\n",
      "<__main__.AddOp object at 0x7f0f405203d0>\n",
      "12\n",
      "first 111111111111111111111\n",
      "None\n",
      "5\n",
      "first 111111111111111111111\n",
      "<__main__.MulOp object at 0x7f0f405202d0>\n",
      "10\n",
      "first 111111111111111111111\n",
      "None\n",
      "2\n",
      "+=\n",
      "None\n",
      "2\n",
      "+=\n",
      "None\n",
      "5\n",
      "6\n",
      "1\n",
      "==================\n",
      "c.op.inputs[0].op.inputs[0] = a + b + a\n"
     ]
    }
   ],
   "source": [
    "graph = Graph()\n",
    "a = graph.tensor(2)\n",
    "b = graph.tensor(5)\n",
    "c = a*b + a -b\n",
    "print(c.initial_value)\n",
    "print(\"==================\")\n",
    "print(a.op)\n",
    "print(b.op)\n",
    "print(c.op)\n",
    "print(\"==================\")\n",
    "#print(\"Length is :\"+str(len(c.op.inputs)))\n",
    "#print(c.op.inputs[0].op)\n",
    "#print(c.op.inputs[1].op)\n",
    "print(c.op.inputs[0].initial_value)\n",
    "print(c.op.inputs[1].initial_value)\n",
    "print(c.op.output.initial_value)\n",
    "print(c.op.output_tensor_with_op.initial_value)\n",
    "print(\"==================\")\n",
    "print(c.initial_value)\n",
    "print(\"==================G\")\n",
    "grad_a, grad_b = graph.gradients(c, [a, b])\n",
    "print(grad_a.initial_value)\n",
    "print(grad_b.initial_value)\n",
    "print(\"==================\")\n",
    "print(\"c.op.inputs[0].op.inputs[0] = a + b + a\")\n",
    "#print(c.op.inputs[0].op.inputs[0].initial_value)\n",
    "#print(c.op.inputs[0].op.inputs[1].initial_value)\n",
    "#sess = Session(graph)\n",
    "#grad_a_, grad_b_ = sess.run([grad_a, grad_b], feed_dict={a: 2, b: 1})\n",
    "#print(grad_a_)\n",
    "#print(grad_b_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "a= 3\n",
    "\n",
    "if type(a) is int:\n",
    "    print(1)\n",
    "else:\n",
    "    print(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=4\n",
    "np.square(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "graph = Graph()\n",
    "a = graph.tensor(2)\n",
    "b = graph.tensor(5)\n",
    "print(graph.square(a).initial_value.initial_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Tensor object at 0x7f0f5c2f4b50>\n",
      "==================\n",
      "None\n",
      "None\n",
      "<__main__.DotOp object at 0x7f0f5c2f4a10>\n",
      "==================\n",
      "[[0 1 2 3]]\n",
      "[[0]\n",
      " [1]\n",
      " [2]\n",
      " [3]]\n",
      "None\n",
      "<__main__.Tensor object at 0x7f0f5c2f4b50>\n",
      "==================\n",
      "<__main__.Tensor object at 0x7f0f5c2f4b50>\n",
      "==================G\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'initial_value'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-bbd1b6c218b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"==================G\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mgrad_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_b\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad_a\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad_b\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-de2064816651>\u001b[0m in \u001b[0;36mgradients\u001b[1;34m(self, y, x_s)\u001b[0m\n\u001b[0;32m     33\u001b[0m                         \u001b[1;31m#print(y.op)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m                         \u001b[0mgradients\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad_y\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#gradients = [grad_y = 1,grad_y = 1] grad_y is a tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m                         \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#len(gradients) = 2, len(y.op.inputs) = 2,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[1;31m#c = a + b + a + a + b/ y = c /  y.op.inputs is [a + b + a + a ,b]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-3e32f859f730>\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(self, grad)\u001b[0m\n\u001b[0;32m    201\u001b[0m         \u001b[0mbT\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m         return [\n\u001b[1;32m--> 203\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    204\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m         ]\n",
      "\u001b[1;32m<ipython-input-5-de2064816651>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(self, a, b)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m                 \u001b[0mop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDotOp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_tensor_with_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-3e32f859f730>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, inputs, graph)\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[0mBaseOp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m         \u001b[1;31m#self.output = graph.convert(   self.compute(inputs[0],inputs[1])   ) #build a tensor object but no op\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 192\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_tensor_with_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m   \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mop\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# build tensor with op=self\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-3e32f859f730>\u001b[0m in \u001b[0;36mcompute\u001b[1;34m(self, a, b)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-68d776f23bcc>\u001b[0m in \u001b[0;36m__mul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__mul__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__truediv__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-de2064816651>\u001b[0m in \u001b[0;36mmul\u001b[1;34m(self, a, b)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                 \u001b[0mop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMulOp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_tensor_with_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-3e32f859f730>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, inputs, graph)\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[0mBaseOp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m   \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;33m)\u001b[0m \u001b[1;31m#build a tensor object but no op\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_tensor_with_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m   \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mop\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# build tensor with op=self\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-3e32f859f730>\u001b[0m in \u001b[0;36mcompute\u001b[1;34m(self, a, b)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitial_value\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-68d776f23bcc>\u001b[0m in \u001b[0;36m__rmul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__rmul__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__rtruediv__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-de2064816651>\u001b[0m in \u001b[0;36mmul\u001b[1;34m(self, a, b)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                 \u001b[0mop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMulOp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_tensor_with_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-3e32f859f730>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, inputs, graph)\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[0mBaseOp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m   \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;33m)\u001b[0m \u001b[1;31m#build a tensor object but no op\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_tensor_with_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m   \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mop\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# build tensor with op=self\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-3e32f859f730>\u001b[0m in \u001b[0;36mcompute\u001b[1;34m(self, a, b)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitial_value\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'int' object has no attribute 'initial_value'"
     ]
    }
   ],
   "source": [
    "graph = Graph()\n",
    "a = graph.tensor(np.array([0,1,2,3]).reshape(1,-1))\n",
    "b = graph.tensor(np.array([0,1,2,3]).reshape(-1,1))\n",
    "c = graph.dot(a,b)\n",
    "print(c.initial_value)\n",
    "print(\"==================\")\n",
    "print(a.op)\n",
    "print(b.op)\n",
    "print(c.op)\n",
    "print(\"==================\")\n",
    "#print(\"Length is :\"+str(len(c.op.inputs)))\n",
    "#print(c.op.inputs[0].op)\n",
    "#print(c.op.inputs[1].op)\n",
    "print(c.op.inputs[0].initial_value)\n",
    "print(c.op.inputs[1].initial_value)\n",
    "print(c.op.output.initial_value)\n",
    "print(c.op.output_tensor_with_op.initial_value)\n",
    "print(\"==================\")\n",
    "print(c.initial_value)\n",
    "print(\"==================G\")\n",
    "grad_a, grad_b = graph.gradients(c, [a, b])\n",
    "print(grad_a.initial_value)\n",
    "print(grad_b.initial_value)\n",
    "print(\"==================\")\n",
    "print(\"c.op.inputs[0].op.inputs[0] = a + b + a\")\n",
    "#print(c.op.inputs[0].op.inputs[0].initial_value)\n",
    "#print(c.op.inputs[0].op.inputs[1].initial_value)\n",
    "#sess = Session(graph)\n",
    "#grad_a_, grad_b_ = sess.run([grad_a, grad_b], feed_dict={a: 2, b: 1})\n",
    "#print(grad_a_)\n",
    "#print(grad_b_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
