{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Tensor(object):\n",
    "    \"\"\"docstring for tensor\"\"\"\n",
    "    def __init__(self, initial_value,op,graph):\n",
    "        self.initial_value = initial_value\n",
    "        self.graph = graph\n",
    "        self.op = op\n",
    "\n",
    "    def __add__(self, other): # change the + operateor's methods, other is another self \n",
    "        return self.graph.add(self, other)\n",
    "    \n",
    "    def __neg__(self):\n",
    "        return self.graph.neg(self)\n",
    "    \n",
    "    def __sub__(self, other):\n",
    "        return self.graph.sub(self, other)\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        return self.graph.mul(self, other)\n",
    "    \n",
    "    def __truediv__(self, other):\n",
    "        return self.graph.div(self, other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class BaseOp(object):\n",
    "    \"\"\"docstring for BaseOp\"\"\"\n",
    "    def __init__(self, inputs,graph):\n",
    "        self.inputs = [graph.convert(input_) for input_ in inputs]\n",
    "        self.output = graph.tensor(op=self)\n",
    "        self.graph  = graph\n",
    "\n",
    "    def compute(self,sess,*args):\n",
    "        raise NotImplementedError()\n",
    "    def gradient(self,grad):\n",
    "        raise NotImplementedError()\n",
    "'''\n",
    "class myParent( object ):\n",
    "    def __init__( self, customParam ):\n",
    "        self.parentNumber = 5\n",
    "        self.customParam = customParam\n",
    "\n",
    "class Child( myParent ):\n",
    "    def __init__( self, customParam ):\n",
    "        myParent.__init__( self, customParam )\n",
    "        self.childNumber = 4        \n",
    "'''        \n",
    "        \n",
    "class AddOp(BaseOp):\n",
    "\n",
    "    \n",
    "    def __init__(self, inputs,graph):\n",
    "        BaseOp.__init__(self, inputs,graph)\n",
    "        self.output = graph.convert(   self.compute(inputs[0],inputs[1])   ) #build a tensor object but no op\n",
    "        self.output_tensor_with_op = graph.tensor(   self.compute(inputs[0],inputs[1]),op =self) # build tensor with op=self\n",
    "        '''\n",
    "        print(\"11111111111 is :\"+str(inputs[0].initial_value))\n",
    "        if inputs[0] is not None and inputs[1] is not None:\n",
    "            self.output = graph.convert(   self.compute(inputs[0],inputs[1])   )\n",
    "        #self.output = graph.convert(1000000000000000000000000000000)\n",
    "    '''\n",
    "    def compute(self,a=0,b=0):\n",
    "        #a = self.inputs[0].initial_value\n",
    "        #b = self.inputs[1].initial_value\n",
    "        return a.initial_value + b.initial_value\n",
    "    def gradient(self,grad):\n",
    "        return [grad,grad]\n",
    "    \n",
    "    \n",
    "    \n",
    "class NegOp(BaseOp):\n",
    "    \"\"\"\n",
    "    `NegOp` negates a tensor.\n",
    "    \"\"\"\n",
    "    def __init__(self, inputs,graph):\n",
    "        BaseOp.__init__(self, inputs,graph)\n",
    "        self.output = graph.convert(   self.compute(inputs[0])   ) #build a tensor object but no op\n",
    "        self.output_tensor_with_op = graph.tensor(   self.compute(inputs[0]),op =self) # build tensor with op=self\n",
    "    \n",
    "    def compute(self,  x):\n",
    "        return -x.initial_value\n",
    "\n",
    "    def gradient(self, grad):\n",
    "        return [-grad]\n",
    "\n",
    "    \n",
    "class SubOp(BaseOp):\n",
    "    \"\"\"\n",
    "    `SubOp` subtracts a tensor from another tensor. Also uses the\n",
    "    [sum rule](https://en.wikipedia.org/wiki/Sum_rule_in_differentiation) to\n",
    "    compute the partial derivatives.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, inputs,graph):\n",
    "        BaseOp.__init__(self, inputs,graph)\n",
    "        self.output = graph.convert(   self.compute(inputs[0],inputs[1])   ) #build a tensor object but no op\n",
    "        self.output_tensor_with_op = graph.tensor(   self.compute(inputs[0],inputs[1]),op =self) # build tensor with op=self\n",
    "    \n",
    "    \n",
    "    def compute(self, a, b):\n",
    "        return a.initial_value - b.initial_value\n",
    "\n",
    "    def gradient(self, grad):\n",
    "        return [grad, -grad]\n",
    "    \n",
    "    \n",
    "class MulOp(BaseOp):\n",
    "    \"\"\"\n",
    "    `MulOp` multiplies a tensor by another tensor. Uses the\n",
    "    [product rule](https://en.wikipedia.org/wiki/Product_rule) to compute the\n",
    "    partial derivatives.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, inputs,graph):\n",
    "        BaseOp.__init__(self, inputs,graph)\n",
    "        self.output = graph.convert(   self.compute(inputs[0],inputs[1])   ) #build a tensor object but no op\n",
    "        self.output_tensor_with_op = graph.tensor(   self.compute(inputs[0],inputs[1]),op =self) # build tensor with op=self\n",
    "    \n",
    "\n",
    "    def compute(self, a, b):\n",
    "        return a.initial_value * b.initial_value\n",
    "\n",
    "    def gradient(self, grad):\n",
    "        a, b = self.inputs\n",
    "        return [grad * b, grad * a]\n",
    "    \n",
    "    \n",
    "class SquareOp(BaseOp):\n",
    "    \"\"\"\n",
    "    `SquareOp` squares a tensor.\n",
    "    \"\"\"\n",
    "    def __init__(self, inputs,graph):\n",
    "        BaseOp.__init__(self, inputs,graph)\n",
    "        self.output = graph.convert(   self.compute(inputs[0])   ) #build a tensor object but no op\n",
    "        self.output_tensor_with_op = graph.tensor(   self.compute(inputs[0]),op =self) # build tensor with op=self\n",
    "    \n",
    "\n",
    "    def compute(self,  x):\n",
    "        return np.square(x)\n",
    "\n",
    "    def gradient(self, grad):\n",
    "        x = self.inputs[0].initial_value\n",
    "        return [grad * (2 * x)]\n",
    "    \n",
    "class DivOp(BaseOp):\n",
    "    \"\"\"\n",
    "    `DivOp` divides a tensor by another tensor. Uses the\n",
    "    [quotient rule](https://en.wikipedia.org/wiki/Quotient_rule) to compute the\n",
    "    partial derivatives.\n",
    "    \"\"\"\n",
    "    def __init__(self, inputs,graph):\n",
    "        BaseOp.__init__(self, inputs,graph)\n",
    "        #self.output = graph.convert(   self.compute(inputs[0],inputs[1])   ) #build a tensor object but no op\n",
    "        self.output_tensor_with_op = graph.tensor(   self.compute(inputs[0],inputs[1]),op =self) # build tensor with op=self\n",
    "    \n",
    "\n",
    "    def compute(self, a, b):\n",
    "\n",
    "        if type(a) is int:\n",
    "            print(\"@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\")\n",
    "            print(type(a))\n",
    "            temp = a/b\n",
    "        else:\n",
    "            print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "            print(type(a))\n",
    "            print(type(b))\n",
    "            print(a.initial_value)\n",
    "            print(b.initial_value)\n",
    "            temp = a.initial_value/b.initial_value\n",
    "        return temp\n",
    "    def gradient(self, grad):\n",
    "        a_, b_ = self.inputs\n",
    "        a=a_.initial_value\n",
    "        b=b_.initial_value\n",
    "        grad_=grad.initial_value\n",
    "        print(\"%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\")\n",
    "        print(type(a))\n",
    "        print(type(b))\n",
    "        print(type(grad))\n",
    "        #grad_=self.graph.tensor(grad)\n",
    "        return [self.graph.tensor(grad_ / b), self.graph.tensor( grad_ * (-a / self.graph.square(b).initial_value)) ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Graph(object):\n",
    "\t\"\"\"docstring for Graph\"\"\"\n",
    "\tdef tensor(self,initial_value=None,op=None):\n",
    "\t\treturn Tensor(initial_value=initial_value,op=op,graph=self)\n",
    "\n",
    "\tdef convert(self,value):\n",
    "\t\tif isinstance(value,Tensor):\n",
    "\t\t\treturn value\n",
    "\t\treturn self.tensor(initial_value=value)\n",
    "\n",
    "\tdef gradients(self,y,x_s):\n",
    "\n",
    "\t\t'''\n",
    "\t\t>>>queue.append(([1,1],1))\n",
    "\t\t>>>queue.pop(0)\n",
    "\t\t([1, 1], 1)\n",
    "\n",
    "\n",
    "\n",
    "    \tloss_op = graph.mean(graph.square(graph.transpose(y) - activations1))\n",
    "    \tparameters = [weights0, biases0, weights1, biases1]\n",
    "\n",
    "    \tgradients = graph.gradients(loss_op, parameters)\n",
    "\t\t'''\n",
    "\t\tqueue = []\n",
    "\t\tqueue.append((y,1)) #queue = [(y,1)]\n",
    "\n",
    "\t\tgrads = {}\n",
    "\n",
    "\t\twhile len(queue)>0:   #len(queue) = 1\n",
    "\t\t\ty,grad_y = queue.pop(0)  # y=y,grad_y =1\n",
    "\t\t\tgrad_y = self.convert(grad_y) #convert grad_y = 1 to a tensor = 1\n",
    "\t\t\t#print(y.op)\n",
    "\n",
    "\t\t\tgradients = y.op.gradient(grad_y) #gradients = [grad_y = 1,grad_y = 1] grad_y is a tensor\n",
    "\t\t\tassert len(gradients) == len(y.op.inputs)#len(gradients) = 2, len(y.op.inputs) = 2, \n",
    "            #c = a + b + a + a + b/ y = c /  y.op.inputs is [a + b + a + a ,b]\n",
    "\n",
    "\t\t\tfor tensor, gradient in zip(y.op.inputs, gradients):\n",
    "                #zip( [a + b + a + a ,b] , [grad_y = 1,grad_y = 1]  )\n",
    "\t\t\t\tif tensor in grads:  # 1: tensor = a + b + a + a , grads = {} \n",
    "                    #2:tensor = b, grads={a + b + a + a:grad_y}\n",
    "\t\t\t\t\tgrads[tensor] += gradient\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tgrads[tensor] = gradient # 1 : grads[a + b + a + a] = gradient(=grad_y) \n",
    "                    #2:grads[b] = gradient(=grad_y)\n",
    "\n",
    "\t\t\t\tif tensor.op:\n",
    "\t\t\t\t\tqueue.append((tensor, gradient)) #queue=[(a + b + a + a,grad_y),(b,grad_y)]\n",
    "                    #**********************************************************\n",
    "                    # for b does not have a op, so tensor.op is None, so queue=[(a+b+a+a,grad_y)] \n",
    "                    # not have (b,grad_y)\n",
    "                    #**********************************************************\n",
    "                    \n",
    "                    \n",
    "            #while len(queue) = 2\n",
    "            #queue.pop(0) = (a + b + a + a,grad_y) => y = a + b + a + a ,grad_y=grad_y=1(tensor)\n",
    "            #......\n",
    "            #while len(queue) = 3\n",
    "            #queue.pop(0) = (b,grad_y) => y = b, grad_y = grad_y = 1\n",
    "            \n",
    "\n",
    "\t\treturn [grads[x] for x in x_s]\n",
    "\n",
    "\n",
    "\tdef add(self,a,b):\n",
    "\t\top = AddOp([a,b],graph=self)\n",
    "\t\treturn op.output_tensor_with_op\n",
    "    \n",
    "\tdef neg(self, x):\n",
    "\t\top = NegOp([x], graph=self)\n",
    "\t\treturn op.output_tensor_with_op\n",
    "    \n",
    "    \n",
    "\tdef sub(self, a, b):\n",
    "\t\top = SubOp([a, b], graph=self)\n",
    "\t\treturn op.output_tensor_with_op\n",
    "    \n",
    "\n",
    "    \n",
    "\tdef mul(self, a, b):\n",
    "\t\top = MulOp([a , b], graph=self)\n",
    "\t\treturn op.output_tensor_with_op\n",
    "    \n",
    "\tdef square(self, x):\n",
    "\t\top = SquareOp([x], graph=self)\n",
    "\t\treturn op.output_tensor_with_op\n",
    "    \n",
    "\tdef div(self, a, b):\n",
    "\t\top = DivOp([a, b], graph=self)\n",
    "\t\treturn op.output_tensor_with_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Session(object):\n",
    "    def __init__(self, graph):\n",
    "        self.graph = graph\n",
    "        self.state = {}\n",
    "        \n",
    "    def run_op(self, op, context):\n",
    "        args = [self.eval_tensor(tensor, context) for tensor in op.inputs]\n",
    "        return op.compute(self, *args)\n",
    "    \n",
    "    def eval_tensor(self, tensor, context):\n",
    "        \n",
    "        if tensor not in context:\n",
    "            if tensor.op is not None:\n",
    "                context[tensor] = self.run_op(tensor.op, context) #let context add the value in op.input\n",
    "            elif tensor in self.state and self.state[tensor] is not None:\n",
    "                context[tensor] = self.state[tensor]              #let context add the value in self.state\n",
    "            elif tensor not in self.state and tensor.initial_value is not None:\n",
    "                context[tensor] = self.state[tensor] = tensor.initial_value\n",
    "                                                        #let context add the value by the initial_value of tensor\n",
    "        return context[tensor]\n",
    "    def run(self, tensors, feed_dict=None):\n",
    "        \n",
    "        context = {}\n",
    "\n",
    "        if feed_dict:\n",
    "            context.update(feed_dict)\n",
    "\n",
    "        return [self.eval_tensor(tensor, context) for tensor in tensors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "==================\n",
      "None\n",
      "None\n",
      "<__main__.AddOp object at 0x7fd84c4e2050>\n",
      "==================\n",
      "Length is :2\n",
      "<__main__.MulOp object at 0x7fd84c4e2550>\n",
      "None\n",
      "10\n",
      "2\n",
      "12\n",
      "12\n",
      "==================\n",
      "12\n",
      "==================G\n",
      "6\n",
      "2\n",
      "==================\n",
      "c.op.inputs[0].op.inputs[0] = a + b + a\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "graph = Graph()\n",
    "a = graph.tensor(2)\n",
    "b = graph.tensor(5)\n",
    "c = a*b+a\n",
    "print(c.initial_value)\n",
    "print(\"==================\")\n",
    "print(a.op)\n",
    "print(b.op)\n",
    "print(c.op)\n",
    "print(\"==================\")\n",
    "print(\"Length is :\"+str(len(c.op.inputs)))\n",
    "print(c.op.inputs[0].op)\n",
    "print(c.op.inputs[1].op)\n",
    "print(c.op.inputs[0].initial_value)\n",
    "print(c.op.inputs[1].initial_value)\n",
    "print(c.op.output.initial_value)\n",
    "print(c.op.output_tensor_with_op.initial_value)\n",
    "print(\"==================\")\n",
    "print(c.initial_value)\n",
    "print(\"==================G\")\n",
    "grad_a, grad_b = graph.gradients(c, [a, b])\n",
    "print(grad_a.initial_value)\n",
    "print(grad_b.initial_value)\n",
    "print(\"==================\")\n",
    "print(\"c.op.inputs[0].op.inputs[0] = a + b + a\")\n",
    "print(c.op.inputs[0].op.inputs[0].initial_value)\n",
    "#print(c.op.inputs[0].op.inputs[1].initial_value)\n",
    "#sess = Session(graph)\n",
    "#grad_a_, grad_b_ = sess.run([grad_a, grad_b], feed_dict={a: 2, b: 1})\n",
    "#print(grad_a_)\n",
    "#print(grad_b_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "==================\n",
      "None\n",
      "None\n",
      "<__main__.MulOp object at 0x7fd84c47cfd0>\n",
      "==================\n",
      "Length is :2\n",
      "None\n",
      "2\n",
      "8\n",
      "8\n",
      "==================\n",
      "8\n",
      "==================G\n",
      "8\n",
      "==================\n",
      "c.op.inputs[0].op.inputs[0] = a + b + a\n"
     ]
    }
   ],
   "source": [
    "graph = Graph()\n",
    "a = graph.tensor(2)\n",
    "b = graph.tensor(5)\n",
    "c = a*(a + a )\n",
    "print(c.initial_value)\n",
    "print(\"==================\")\n",
    "print(a.op)\n",
    "print(b.op)\n",
    "print(c.op)\n",
    "print(\"==================\")\n",
    "print(\"Length is :\"+str(len(c.op.inputs)))\n",
    "print(c.op.inputs[0].op)\n",
    "print(c.op.inputs[0].initial_value)\n",
    "print(c.op.output.initial_value)\n",
    "print(c.op.output_tensor_with_op.initial_value)\n",
    "print(\"==================\")\n",
    "print(c.initial_value)\n",
    "print(\"==================G\")\n",
    "grad_a= graph.gradients(c, [a])\n",
    "print(grad_a[0].initial_value)\n",
    "print(\"==================\")\n",
    "print(\"c.op.inputs[0].op.inputs[0] = a + b + a\")\n",
    "#print(c.op.inputs[0].op.inputs[0].initial_value)\n",
    "#print(c.op.inputs[0].op.inputs[1].initial_value)\n",
    "#sess = Session(graph)\n",
    "#grad_a_, grad_b_ = sess.run([grad_a, grad_b], feed_dict={a: 2, b: 1})\n",
    "#print(grad_a_)\n",
    "#print(grad_b_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "<class '__main__.Tensor'>\n",
      "<class '__main__.Tensor'>\n",
      "2\n",
      "12\n",
      "23.1666666667\n",
      "==================\n",
      "None\n",
      "None\n",
      "<__main__.AddOp object at 0x7fd84c4e71d0>\n",
      "==================\n",
      "3.16666666667\n",
      "20\n",
      "23.1666666667\n",
      "23.1666666667\n",
      "==================\n",
      "23.1666666667\n",
      "==================G\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "<type 'int'>\n",
      "<type 'int'>\n",
      "<class '__main__.Tensor'>\n",
      "19.0694444444\n",
      "4.97222222222\n",
      "==================\n",
      "c.op.inputs[0].op.inputs[0] = a + b + a\n"
     ]
    }
   ],
   "source": [
    "graph = Graph()\n",
    "a = graph.tensor(2)\n",
    "b = graph.tensor(5)\n",
    "c = a/(b+b+a) - a +b + a*a*b\n",
    "print(c.initial_value)\n",
    "print(\"==================\")\n",
    "print(a.op)\n",
    "print(b.op)\n",
    "print(c.op)\n",
    "print(\"==================\")\n",
    "#print(\"Length is :\"+str(len(c.op.inputs)))\n",
    "#print(c.op.inputs[0].op)\n",
    "#print(c.op.inputs[1].op)\n",
    "print(c.op.inputs[0].initial_value)\n",
    "print(c.op.inputs[1].initial_value)\n",
    "print(c.op.output.initial_value)\n",
    "print(c.op.output_tensor_with_op.initial_value)\n",
    "print(\"==================\")\n",
    "print(c.initial_value)\n",
    "print(\"==================G\")\n",
    "grad_a, grad_b = graph.gradients(c, [a, b])\n",
    "print(grad_a.initial_value)\n",
    "print(grad_b.initial_value)\n",
    "print(\"==================\")\n",
    "print(\"c.op.inputs[0].op.inputs[0] = a + b + a\")\n",
    "#print(c.op.inputs[0].op.inputs[0].initial_value)\n",
    "#print(c.op.inputs[0].op.inputs[1].initial_value)\n",
    "#sess = Session(graph)\n",
    "#grad_a_, grad_b_ = sess.run([grad_a, grad_b], feed_dict={a: 2, b: 1})\n",
    "#print(grad_a_)\n",
    "#print(grad_b_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "a= 3\n",
    "\n",
    "if type(a) is int:\n",
    "    print(1)\n",
    "else:\n",
    "    print(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=4\n",
    "np.square(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "graph = Graph()\n",
    "a = graph.tensor(2)\n",
    "b = graph.tensor(5)\n",
    "print(graph.square(a).initial_value.initial_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
